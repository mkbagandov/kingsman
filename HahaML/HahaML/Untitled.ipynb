{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cd0a299-6b19-4ec7-822a-18463cffc590",
   "metadata": {},
   "source": [
    "# Zero-Shot –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ–¥–µ–∂–¥—ã \n",
    "\n",
    "## üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞\n",
    "\n",
    "```bash\n",
    "# —Å–æ–∑–¥–∞—Ç—å –∏ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –æ–∫—Ä—É–∂–µ–Ω–∏–µ (–ø–æ –∂–µ–ª–∞–Ω–∏—é)\n",
    "python -m venv venv\n",
    "source venv/bin/activate   # Linux/Mac\n",
    "venv\\Scripts\\activate      # Windows\n",
    "\n",
    "# —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏\n",
    "pip install transformers torch sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e99d6575-cadf-4566-882c-009124084ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at joeddav/xlm-roberta-large-xnli were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé –†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:\n",
      "–ö–æ—Å—Ç—é–º—ã         ‚Äî 20.75%\n",
      "–í–µ—Ä—Ö–Ω—è—è –æ–¥–µ–∂–¥–∞  ‚Äî 16.47%\n",
      "–û–±—É–≤—å           ‚Äî 11.23%\n",
      "–ì–∞–ª—Å—Ç—É–∫–∏        ‚Äî 9.27%\n",
      "–®–æ—Ä—Ç—ã           ‚Äî 7.46%\n",
      "–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã      ‚Äî 7.02%\n",
      "–†–µ–º–Ω–∏           ‚Äî 6.99%\n",
      "–ù–æ—Å–∫–∏           ‚Äî 5.43%\n",
      "–ü–∏–¥–∂–∞–∫–∏         ‚Äî 3.11%\n",
      "–°–≤–∏—Ç–µ—Ä—ã         ‚Äî 3.06%\n",
      "–î–∂–∏–Ω—Å—ã          ‚Äî 2.52%\n",
      "–†—É–±–∞—à–∫–∏         ‚Äî 2.36%\n",
      "–§—É—Ç–±–æ–ª–∫–∏        ‚Äî 1.91%\n",
      "–ë—Ä—é–∫–∏           ‚Äî 1.41%\n",
      "–ë–ª–µ–π–∑–µ—Ä—ã        ‚Äî 1.02%\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, XLMRobertaTokenizer\n",
    "\n",
    "model_name = \"joeddav/xlm-roberta-large-xnli\"\n",
    "\n",
    "# –∑–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏ –º–æ–¥–µ–ª—å\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=model_name,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# —Ç–≤–æ–π –∑–∞–ø—Ä–æ—Å\n",
    "sequence = \"–•–æ—á—É –ø–æ–¥–æ–±—Ä–∞—Ç—å —á—Ç–æ-—Ç–æ –¥–ª—è –∑–∏–º—ã\"\n",
    "\n",
    "# —Ç–≤–æ–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ –ë–î\n",
    "candidate_labels = [\n",
    "    \"–ë—Ä—é–∫–∏\",\n",
    "    \"–ü–∏–¥–∂–∞–∫–∏\",\n",
    "    \"–†—É–±–∞—à–∫–∏\",\n",
    "    \"–û–±—É–≤—å\",\n",
    "    \"–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã\",\n",
    "    \"–ö–æ—Å—Ç—é–º—ã\",\n",
    "    \"–§—É—Ç–±–æ–ª–∫–∏\",\n",
    "    \"–°–≤–∏—Ç–µ—Ä—ã\",\n",
    "    \"–®–æ—Ä—Ç—ã\",\n",
    "    \"–í–µ—Ä—Ö–Ω—è—è –æ–¥–µ–∂–¥–∞\",\n",
    "    \"–î–∂–∏–Ω—Å—ã\",\n",
    "    \"–ë–ª–µ–π–∑–µ—Ä—ã\",\n",
    "    \"–ì–∞–ª—Å—Ç—É–∫–∏\",\n",
    "    \"–†–µ–º–Ω–∏\",\n",
    "    \"–ù–æ—Å–∫–∏\"\n",
    "]\n",
    "\n",
    "# —à–∞–±–ª–æ–Ω –¥–ª—è NLI (—á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –ø–æ–Ω–∏–º–∞–ª–∞ —Å–≤—è–∑—å –∑–∞–ø—Ä–æ—Å–∞ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–µ–π)\n",
    "result = classifier(\n",
    "    sequence,\n",
    "    candidate_labels=candidate_labels,\n",
    "    hypothesis_template=\"–≠—Ç–æ—Ç –∑–∞–ø—Ä–æ—Å —Å–≤—è–∑–∞–Ω —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–µ–π {}.\"\n",
    ")\n",
    "\n",
    "# –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —É–¥–æ–±–Ω—ã–π –≤–∏–¥ —Å –ø—Ä–æ—Ü–µ–Ω—Ç–∞–º–∏\n",
    "labels_with_scores = list(zip(result[\"labels\"], result[\"scores\"]))\n",
    "labels_with_scores.sort(key=lambda x: x[1], reverse=True)  # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏\n",
    "\n",
    "print(\"üîé –†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:\")\n",
    "for label, score in labels_with_scores:\n",
    "    print(f\"{label:15} ‚Äî {score*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (clothes)",
   "language": "python",
   "name": "venv_clothes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
